{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1\n",
    "### 1) Preprocess your Titanic training data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "combine = [train_df, test_df]\n",
    "# list(train_df)\n",
    "print(train_df.columns.values)\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    646\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  \n",
       "0         A/5 21171   7.2500   NaN         2  \n",
       "1          PC 17599  71.2833   C85         1  \n",
       "2  STON/O2. 3101282   7.9250   NaN         2  \n",
       "3            113803  53.1000  C123         2  \n",
       "4            373450   8.0500   NaN         2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN Mean for Age\n",
    "train_df['Age'].fillna(value=train_df['Age'].mean(), inplace=True)\n",
    "# Mode for Embarked\n",
    "train_df['Embarked'].fillna(value=train_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Rename Sex Value\n",
    "train_df['Sex'] = train_df['Sex'].replace('female',1)\n",
    "train_df['Sex'] = train_df['Sex'].replace('male',0)\n",
    "\n",
    "# Rename Embarked Value\n",
    "print(train_df['Embarked'].value_counts())    # Repeat times for S,C,Q\n",
    "train_df['Embarked'] = train_df['Embarked'].replace('S',2)\n",
    "train_df['Embarked'] = train_df['Embarked'].replace('C',1)\n",
    "train_df['Embarked'] = train_df['Embarked'].replace('Q',0)\n",
    "\n",
    "# train_df.isnull().sum()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Select a set of important features. Please show your selected features and explain how you perform feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model shape:  (891, 7)\n",
      "model scores: [3.08736994e+01 1.70348127e+02 2.46879258e+01 2.58186538e+00\n",
      " 1.00974991e+01 4.51831909e+03 2.50390659e+00]\n",
      "model p-values [2.75378563e-08 6.21058490e-39 6.74051416e-07 1.08094210e-01\n",
      " 1.48470676e-03 0.00000000e+00 1.13564280e-01]\n",
      "k best features are:  ['Fare', 'Sex', 'Pclass', 'Age', 'Parch', 'SibSp', 'Embarked']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\envs\\pytorch_study\\lib\\site-packages\\pandas\\core\\series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fare', 'Sex', 'Pclass', 'Age', 'Parch', 'SibSp', 'Embarked']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because everyone has a different PassengerId, Name, Ticket, and there are too many NaN value on Cabine, \n",
    "# these 4 features will be not used for feature selection\n",
    "\n",
    "def get_feature_importance():\n",
    "\n",
    "    feature_data = train_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "    label_data = train_df['Survived']\n",
    "    \n",
    "    feature_data['Age'].fillna(feature_data['Age'].mean(), inplace=True)\n",
    "    \n",
    "    # Select K best features\n",
    "    k=7\n",
    "    model = SelectKBest(chi2, k=k)\n",
    "    X_new = model.fit_transform(feature_data, label_data)\n",
    " \n",
    "    print(\"model shape: \",X_new.shape)\n",
    "    \n",
    "    # Higher Score = Highly Important Feature\n",
    "    scores = model.scores_\n",
    "    print('model scores:', scores)\n",
    "     \n",
    "    # Smaller Pvalue = Highly Important Feature\n",
    "    p_values = model.pvalues_\n",
    "    print('model p-values', p_values) \n",
    " \n",
    "    # From the K features, sort by Importance \n",
    "    indices = np.argsort(scores)[::-1]\n",
    "    k_best_features = list(feature_data.columns.values[indices[0:k]])\n",
    "    print('k best features are: ',k_best_features)\n",
    "    \n",
    "    return k_best_features\n",
    "\n",
    "get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Learn a decision tree model with the Titanic training data using Gini index, plot your decision tree;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Fare', 'Parch', 'Pclass', 'Sex']\n",
      "[[22.          7.25        0.          3.          0.        ]\n",
      " [38.         71.2833      0.          1.          1.        ]\n",
      " [26.          7.925       0.          3.          1.        ]\n",
      " ...\n",
      " [29.69911765 23.45        2.          3.          1.        ]\n",
      " [26.         30.          0.          1.          0.        ]\n",
      " [32.          7.75        0.          3.          0.        ]]\n",
      "Accuracy： 0.8022388059701493\n"
     ]
    }
   ],
   "source": [
    "def decision():\n",
    "\n",
    "    train = train_df[['Fare', 'Sex', 'Pclass', 'Age', 'Parch']]\n",
    "    label = train_df['Survived']\n",
    "\n",
    "    # one-hot on features\n",
    "    dic = DictVectorizer(sparse=False)\n",
    "    train = dic.fit_transform(train.to_dict(orient=\"records\"))\n",
    "\n",
    "    print(dic.get_feature_names())\n",
    "    print(train)\n",
    "\n",
    "    # Sperate training data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train, label, test_size=0.3)\n",
    "\n",
    "    # Decision tree model\n",
    "    dec = DecisionTreeClassifier(criterion=\"gini\", max_depth=5)\n",
    "\n",
    "    dec.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Accuracy：\", dec.score(x_test, y_test))\n",
    "    \n",
    "    # export a dec tree\n",
    "    export_graphviz(dec, out_file=\"./tree.dot\", feature_names=['Fare', 'Sex', 'Pclass', 'Age', 'Parch'])\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    decision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on Ubuntu terminal\n",
    "# $ sudo apt install graphviz\n",
    "# $ dot -Tpng  tree.dot  -o tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "image/png": {
       "height": 100,
       "width": 100
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename = \"tree.png\", width=100, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Apply the five-fold cross validation of the decision tree learning algorithm to the Titanic training data to extract average classification accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Fare', 'Parch', 'Pclass', 'Sex']\n",
      "[[22.          7.25        0.          3.          0.        ]\n",
      " [38.         71.2833      0.          1.          1.        ]\n",
      " [26.          7.925       0.          3.          1.        ]\n",
      " ...\n",
      " [29.69911765 23.45        2.          3.          1.        ]\n",
      " [26.         30.          0.          1.          0.        ]\n",
      " [32.          7.75        0.          3.          0.        ]]\n",
      "Accuracy: 0.835820895522388\n",
      "Score: 0.8025935483870967\n",
      "Estimator: DecisionTreeClassifier(max_depth=5, max_features=5)\n",
      "Result: {'mean_fit_time': array([0.        , 0.00100002, 0.00099988, 0.00100055, 0.        ,\n",
      "       0.        , 0.00099998, 0.00099988, 0.00039968, 0.00059991,\n",
      "       0.00080061, 0.        , 0.00039992, 0.00100012, 0.00059996,\n",
      "       0.00100002, 0.00100002, 0.00099993, 0.00039935, 0.00080066,\n",
      "       0.00019937, 0.00099978, 0.00100007, 0.00060005, 0.00079989]), 'std_fit_time': array([0.00000000e+00, 1.92278339e-06, 1.51090427e-06, 2.03104644e-05,\n",
      "       0.00000000e+00, 0.00000000e+00, 1.70198138e-06, 1.92750768e-06,\n",
      "       4.89512875e-04, 4.89825859e-04, 4.00307081e-04, 0.00000000e+00,\n",
      "       4.89804093e-04, 3.50402318e-07, 4.89862534e-04, 1.90734863e-07,\n",
      "       5.56082906e-07, 3.01578299e-07, 4.89104544e-04, 4.00333134e-04,\n",
      "       3.98731232e-04, 2.57050170e-06, 1.92278339e-06, 4.89940316e-04,\n",
      "       3.99947319e-04]), 'mean_score_time': array([0.        , 0.00020027, 0.        , 0.        , 0.00040002,\n",
      "       0.00020008, 0.        , 0.        , 0.        , 0.00039964,\n",
      "       0.00019999, 0.00100002, 0.0006    , 0.        , 0.00019999,\n",
      "       0.        , 0.        , 0.        , 0.00020022, 0.00019951,\n",
      "       0.00080123, 0.        , 0.        , 0.00019989, 0.00019999]), 'std_score_time': array([0.00000000e+00, 4.00543213e-04, 0.00000000e+00, 0.00000000e+00,\n",
      "       4.89921126e-04, 4.00161743e-04, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 4.89454620e-04, 3.99971008e-04, 2.43140197e-07,\n",
      "       4.89901429e-04, 0.00000000e+00, 3.99971008e-04, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 4.00447845e-04, 3.99017334e-04,\n",
      "       4.00615061e-04, 0.00000000e+00, 0.00000000e+00, 3.99780273e-04,\n",
      "       3.99971008e-04]), 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7,\n",
      "                   7, 7, 8, 8, 8, 8, 8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=[1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3,\n",
      "                   4, 5, 1, 2, 3, 4, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 4, 'max_features': 1}, {'max_depth': 4, 'max_features': 2}, {'max_depth': 4, 'max_features': 3}, {'max_depth': 4, 'max_features': 4}, {'max_depth': 4, 'max_features': 5}, {'max_depth': 5, 'max_features': 1}, {'max_depth': 5, 'max_features': 2}, {'max_depth': 5, 'max_features': 3}, {'max_depth': 5, 'max_features': 4}, {'max_depth': 5, 'max_features': 5}, {'max_depth': 6, 'max_features': 1}, {'max_depth': 6, 'max_features': 2}, {'max_depth': 6, 'max_features': 3}, {'max_depth': 6, 'max_features': 4}, {'max_depth': 6, 'max_features': 5}, {'max_depth': 7, 'max_features': 1}, {'max_depth': 7, 'max_features': 2}, {'max_depth': 7, 'max_features': 3}, {'max_depth': 7, 'max_features': 4}, {'max_depth': 7, 'max_features': 5}, {'max_depth': 8, 'max_features': 1}, {'max_depth': 8, 'max_features': 2}, {'max_depth': 8, 'max_features': 3}, {'max_depth': 8, 'max_features': 4}, {'max_depth': 8, 'max_features': 5}], 'split0_test_score': array([0.776, 0.768, 0.776, 0.776, 0.776, 0.648, 0.76 , 0.792, 0.752,\n",
      "       0.768, 0.768, 0.784, 0.8  , 0.784, 0.752, 0.68 , 0.76 , 0.784,\n",
      "       0.752, 0.76 , 0.68 , 0.744, 0.728, 0.752, 0.784]), 'split1_test_score': array([0.68 , 0.736, 0.744, 0.8  , 0.792, 0.792, 0.752, 0.816, 0.784,\n",
      "       0.784, 0.776, 0.776, 0.76 , 0.752, 0.768, 0.704, 0.76 , 0.736,\n",
      "       0.736, 0.72 , 0.736, 0.728, 0.688, 0.76 , 0.744]), 'split2_test_score': array([0.624, 0.76 , 0.816, 0.808, 0.832, 0.792, 0.664, 0.84 , 0.832,\n",
      "       0.84 , 0.72 , 0.8  , 0.768, 0.792, 0.776, 0.8  , 0.76 , 0.808,\n",
      "       0.784, 0.792, 0.776, 0.704, 0.792, 0.768, 0.784]), 'split3_test_score': array([0.77419355, 0.7016129 , 0.82258065, 0.79032258, 0.7983871 ,\n",
      "       0.67741935, 0.78225806, 0.75      , 0.82258065, 0.82258065,\n",
      "       0.75      , 0.81451613, 0.83064516, 0.78225806, 0.82258065,\n",
      "       0.75      , 0.83064516, 0.7983871 , 0.81451613, 0.83870968,\n",
      "       0.7983871 , 0.78225806, 0.79032258, 0.79032258, 0.82258065]), 'split4_test_score': array([0.76612903, 0.7983871 , 0.79032258, 0.7983871 , 0.7983871 ,\n",
      "       0.76612903, 0.77419355, 0.78225806, 0.78225806, 0.7983871 ,\n",
      "       0.78225806, 0.81451613, 0.7983871 , 0.78225806, 0.77419355,\n",
      "       0.80645161, 0.75      , 0.75806452, 0.72580645, 0.76612903,\n",
      "       0.80645161, 0.81451613, 0.7983871 , 0.76612903, 0.74193548]), 'mean_test_score': array([0.72406452, 0.7528    , 0.78978065, 0.79454194, 0.79935484,\n",
      "       0.73510968, 0.74649032, 0.79605161, 0.79456774, 0.80259355,\n",
      "       0.75925161, 0.79780645, 0.79140645, 0.77850323, 0.77855484,\n",
      "       0.74809032, 0.77212903, 0.77689032, 0.76246452, 0.77536774,\n",
      "       0.75936774, 0.75455484, 0.75934194, 0.76729032, 0.77530323]), 'std_test_score': array([0.06153735, 0.0324451 , 0.02845826, 0.01083791, 0.01825991,\n",
      "       0.06058298, 0.04257774, 0.03051828, 0.02919286, 0.02591854,\n",
      "       0.02241705, 0.01568042, 0.02528431, 0.01373314, 0.02358128,\n",
      "       0.05036775, 0.02951329, 0.02648358, 0.03263997, 0.03918148,\n",
      "       0.04660756, 0.03933238, 0.04386995, 0.01280062, 0.02993232]), 'rank_test_score': array([25, 21,  8,  6,  2, 24, 23,  4,  5,  1, 19,  3,  7, 10,  9, 22, 14,\n",
      "       11, 16, 12, 17, 20, 18, 15, 13])}\n"
     ]
    }
   ],
   "source": [
    "def decision_cv():\n",
    "\n",
    "    train = train_df[['Fare', 'Sex', 'Pclass', 'Age', 'Parch']]\n",
    "    label = train_df['Survived']\n",
    "\n",
    "    # one-hot on features\n",
    "    dic = DictVectorizer(sparse=False)\n",
    "    train = dic.fit_transform(train.to_dict(orient=\"records\"))\n",
    "\n",
    "    print(dic.get_feature_names())\n",
    "    print(train)\n",
    "\n",
    "    # Sperate training data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train, label, test_size=0.3)\n",
    "\n",
    "    # Decision tree model\n",
    "    dec = DecisionTreeClassifier(criterion=\"gini\")\n",
    "    \n",
    "    param = {'max_features': [1, 2, 3, 4, 5], \"max_depth\":[4,5,6,7,8]}\n",
    "    gc = GridSearchCV(dec, param_grid=param, cv=5)\n",
    "    \n",
    "    gc.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Accuracy:\", gc.score(x_test, y_test))\n",
    "    print(\"Score:\", gc.best_score_)\n",
    "    print(\"Estimator:\",gc.best_estimator_)\n",
    "    print(\"Result:\", gc.cv_results_)\n",
    "    \n",
    "    \n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    decision_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Apply the five-fold cross validation of the random forest learning algorithm to the Titanic training data to extract average classification accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp']\n",
      "[[22.          2.          7.25       ...  3.          0.\n",
      "   1.        ]\n",
      " [38.          1.         71.2833     ...  1.          1.\n",
      "   1.        ]\n",
      " [26.          2.          7.925      ...  3.          1.\n",
      "   0.        ]\n",
      " ...\n",
      " [29.69911765  2.         23.45       ...  3.          1.\n",
      "   1.        ]\n",
      " [26.          1.         30.         ...  1.          0.\n",
      "   0.        ]\n",
      " [32.          0.          7.75       ...  3.          0.\n",
      "   0.        ]]\n",
      "RF accuracy 0.8470149253731343\n",
      "Best combination:  RandomForestClassifier(max_depth=9, min_samples_split=3, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction import DictVectorizer\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def randomForest():\n",
    "    # train = train_df[['Fare', 'Sex', 'Pclass', 'Age', 'Parch']]    # accuracy : 0.821\n",
    "    train = train_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]    # accuracy 0.847\n",
    "    label = train_df['Survived']\n",
    "\n",
    "    # one-hot on features\n",
    "    dic = DictVectorizer(sparse=False)\n",
    "    train = dic.fit_transform(train.to_dict(orient=\"records\"))\n",
    "\n",
    "    print(dic.get_feature_names())\n",
    "    print(train)\n",
    "\n",
    "    # Sperate training data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train, label, test_size=0.3)\n",
    "\n",
    "    # rf for prediction\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # n_estimators = num of trees\n",
    "    param = {\"n_estimators\":[120,200,300,500,800,1200],\n",
    "             \"max_depth\":[5,7,9,11,12],\n",
    "             \"min_samples_split\":[2,3,5]}\n",
    "\n",
    "\n",
    "    # Every possible parameter combination\n",
    "    gc = GridSearchCV(rf, param_grid=param, cv=5)\n",
    "    gc.fit(x_train,y_train)\n",
    "    print(\"RF accuracy\", gc.score(x_test,y_test))\n",
    "    print(\"Best combination: \", gc.best_estimator_)\n",
    "    \n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    randomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_df['Survived']))\n",
    "train_df['Survived'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  Class Label\n",
       "0  1  0            1\n",
       "1  1  1            1\n",
       "2  1  1            1\n",
       "3  1  0            0\n",
       "4  1  1            1\n",
       "5  0  0            0\n",
       "6  0  0            0\n",
       "7  0  0            0\n",
       "8  1  1            0\n",
       "9  1  0            0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[1,1,1,1,1,0,0,0,1,1],[0,1,1,0,1,0,0,0,1,0],[1,1,1,0,1,0,0,0,0,0]])\n",
    "df_data = pd.DataFrame(data,dtype=int).T\n",
    "\n",
    "df_data.columns = [\"A\", \"B\", \"Class Label\"]\n",
    "\n",
    "#print(x.shape) , columns = [\"A\", \"B\", \"C\"]\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B']\n",
      "[[1. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]]\n",
      "Accuracy： 1.0\n"
     ]
    }
   ],
   "source": [
    "def decision():\n",
    "    \n",
    "    train = df_data[['A','B']]\n",
    "    label = df_data['Class Label']\n",
    "    # one-hot on features\n",
    "    dic = DictVectorizer(sparse=False)\n",
    "    train = dic.fit_transform(train.to_dict(orient=\"records\"))\n",
    "\n",
    "    print(dic.get_feature_names())\n",
    "    print(train)\n",
    "\n",
    "    # Sperate training data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train, label, test_size=0.3)\n",
    "\n",
    "    # Decision tree model\n",
    "    dec = DecisionTreeClassifier(criterion=\"entropy\", \n",
    "                                 max_depth=3)\n",
    "\n",
    "    dec.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Accuracy：\", dec.score(x_test, y_test))\n",
    "    \n",
    "    # export a dec tree\n",
    "    export_graphviz(dec, out_file=\"./test.dot\", feature_names=['A', 'B'])\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    decision()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
